"""
GNNå„ªç§€äººæåˆ†æã‚·ã‚¹ãƒ†ãƒ  - Streamlitã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
import logging
from gnn_talent_analyzer import (
    TalentAnalyzer,
    DataValidationError,
    DataLoadingError,
    ModelTrainingError,
    ModelEvaluationError,
    CausalInferenceError,
    AnalysisError
)
from config_loader import get_config

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logger = logging.getLogger('TalentAnalyzer')

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title=get_config('ui.page_title', 'GNNå„ªç§€äººæåˆ†æã‚·ã‚¹ãƒ†ãƒ '),
    page_icon=get_config('ui.page_icon', 'ğŸ¯'),
    layout="wide"
)

# è¨­å®šå€¤ã®å–å¾—
MIN_EXCELLENT = get_config('analysis.min_excellent_members', 3)
MAX_EXCELLENT_RECOMMENDED = get_config('analysis.max_excellent_members_recommended', 20)
ESSENTIAL_THRESHOLD = get_config('analysis.essential_skill_threshold', 0.8)
IMPORTANT_DIFF_THRESHOLD = get_config('analysis.important_skill_diff_threshold', 0.3)
SIGNIFICANT_DIFF_THRESHOLD = get_config('analysis.significant_skill_diff_threshold', 0.2)

COLOR_EXCELLENT = get_config('ui.colors.excellent_group', '#FF6B6B')
COLOR_NON_EXCELLENT = get_config('ui.colors.non_excellent_group', '#4ECDC4')

TOP_SKILLS_CHART = get_config('ui.display.top_skills_chart', 15)
MEMBER_SCORES_HEIGHT = get_config('ui.display.member_scores_height', 400)
CHART_HEIGHT = get_config('ui.display.chart_height', 600)
HISTOGRAM_BINS = get_config('ui.display.histogram_bins', 20)

MIN_EPOCHS = get_config('training.min_epochs', 50)
MAX_EPOCHS = get_config('training.max_epochs', 500)
DEFAULT_EPOCHS = get_config('training.default_epochs', 100)

EXPORT_SKILL_FILE = get_config('files.export.skill_importance', 'skill_importance.csv')
EXPORT_MEMBER_FILE = get_config('files.export.member_scores', 'member_scores.csv')
FILE_ENCODING = get_config('files.encoding', 'utf-8-sig')

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'analyzer' not in st.session_state:
    st.session_state.analyzer = None
if 'data_loaded' not in st.session_state:
    st.session_state.data_loaded = False
if 'results' not in st.session_state:
    st.session_state.results = None
if 'evaluation_results' not in st.session_state:
    st.session_state.evaluation_results = None
if 'causal_results' not in st.session_state:
    st.session_state.causal_results = None
if 'interaction_results' not in st.session_state:
    st.session_state.interaction_results = None
if 'member_df' not in st.session_state:
    st.session_state.member_df = None

# ã‚¿ã‚¤ãƒˆãƒ«
st.title(f"{get_config('ui.page_icon', 'ğŸ¯')} {get_config('ui.page_title', 'GNNå„ªç§€äººæåˆ†æã‚·ã‚¹ãƒ†ãƒ ')}")
st.markdown("---")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
st.sidebar.header("ğŸ“ ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded_files = {
    'member': st.sidebar.file_uploader("ç¤¾å“¡ãƒã‚¹ã‚¿ (member_skillnote.csv)", type=['csv']),
    'acquired': st.sidebar.file_uploader("ã‚¹ã‚­ãƒ«ç¿’å¾—ãƒ‡ãƒ¼ã‚¿ (acquiredCompetenceLevel.csv)", type=['csv']),
    'skill': st.sidebar.file_uploader("ã‚¹ã‚­ãƒ«ãƒã‚¹ã‚¿ (skill_skillnote.csv)", type=['csv']),
    'education': st.sidebar.file_uploader("æ•™è‚²ãƒã‚¹ã‚¿ (education_skillnote.csv)", type=['csv']),
    'license': st.sidebar.file_uploader("è³‡æ ¼ãƒã‚¹ã‚¿ (license_skillnote.csv)", type=['csv'])
}

# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒœã‚¿ãƒ³
if st.sidebar.button("ğŸ“Š ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"):
    if all(uploaded_files.values()):
        try:
            with st.spinner("ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­..."):
                # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
                try:
                    member_df = pd.read_csv(uploaded_files['member'], encoding=FILE_ENCODING)
                    acquired_df = pd.read_csv(uploaded_files['acquired'], encoding=FILE_ENCODING)
                    skill_df = pd.read_csv(uploaded_files['skill'], encoding=FILE_ENCODING)
                    education_df = pd.read_csv(uploaded_files['education'], encoding=FILE_ENCODING)
                    license_df = pd.read_csv(uploaded_files['license'], encoding=FILE_ENCODING)
                except pd.errors.ParserError as e:
                    logger.error(f"CSVè§£æã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
                    st.sidebar.error(
                        f"âŒ CSVå½¢å¼ãŒç„¡åŠ¹ã§ã™ã€‚ã‚«ãƒ©ãƒ åã¨å‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n"
                        f"è©³ç´°: {str(e)}"
                    )
                    raise DataLoadingError(f"CSVè§£æå¤±æ•—: {e}") from e
                except FileNotFoundError as e:
                    logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}", exc_info=True)
                    st.sidebar.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {str(e)}")
                    raise DataLoadingError(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}") from e

                # ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ã®åˆæœŸåŒ–
                analyzer = TalentAnalyzer()
                analyzer.load_data(member_df, acquired_df, skill_df, education_df, license_df)

                st.session_state.analyzer = analyzer
                st.session_state.member_df = member_df
                st.session_state.data_loaded = True

                st.sidebar.success("âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†")
        except DataValidationError as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            st.sidebar.error(f"âŒ ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {str(e)}")
        except DataLoadingError as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            st.sidebar.error(f"âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
        except Exception as e:
            logger.error(f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", exc_info=True)
            st.sidebar.error(
                f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚\n"
                f"ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã¨ãƒ‡ãƒ¼ã‚¿å†…å®¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n"
                f"è©³ç´°: {str(e)}"
            )
    else:
        st.sidebar.warning("âš ï¸ ã™ã¹ã¦ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")

st.sidebar.markdown("---")

# ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
if st.session_state.data_loaded:
    analyzer = st.session_state.analyzer

    # ãƒ‡ãƒ¼ã‚¿æ¦‚è¦
    with st.expander("ğŸ“Š ãƒ‡ãƒ¼ã‚¿æ¦‚è¦", expanded=False):
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric("ç·ç¤¾å“¡æ•°", len(analyzer.members))
        with col2:
            st.metric("ã‚¹ã‚­ãƒ«ç¨®é¡æ•°", len(analyzer.skill_codes))
        with col3:
            avg_skills = np.mean(np.sum(analyzer.skill_matrix > 0, axis=1))
            st.metric("å¹³å‡ã‚¹ã‚­ãƒ«ä¿æœ‰æ•°", f"{avg_skills:.1f}")
        with col4:
            sparsity = 1 - np.count_nonzero(analyzer.skill_matrix) / analyzer.skill_matrix.size
            st.metric("ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§", f"{sparsity*100:.1f}%")

    st.markdown("---")

    # å„ªç§€äººæé¸æŠ
    st.header("1ï¸âƒ£ å„ªç§€äººæã®é¸æŠ")

    # ç¤¾å“¡ãƒªã‚¹ãƒˆã®è¡¨ç¤º
    member_list = []
    for member_code in analyzer.members:
        member_name = analyzer.member_names.get(member_code, 'ä¸æ˜')
        n_skills = int(np.sum(analyzer.skill_matrix[analyzer.member_to_idx[member_code]] > 0))
        member_list.append({
            'ã‚³ãƒ¼ãƒ‰': member_code,
            'åå‰': member_name,
            'ã‚¹ã‚­ãƒ«ä¿æœ‰æ•°': n_skills
        })

    member_df_display = pd.DataFrame(member_list)

    # é¸æŠæ–¹æ³•
    selection_method = st.radio(
        "é¸æŠæ–¹æ³•",
        ["æ‰‹å‹•é¸æŠ", "ã‚¹ã‚­ãƒ«ä¿æœ‰æ•°ä¸Šä½ã‚’è‡ªå‹•é¸æŠ"],
        horizontal=True
    )

    if selection_method == "æ‰‹å‹•é¸æŠ":
        # ãƒãƒ«ãƒã‚»ãƒ¬ã‚¯ãƒˆ
        selected_members = st.multiselect(
            f"å„ªç§€ãªç¤¾å“¡ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼ˆ5-{MAX_EXCELLENT_RECOMMENDED}åæ¨å¥¨ï¼‰",
            options=member_df_display['ã‚³ãƒ¼ãƒ‰'].tolist(),
            format_func=lambda x: f"{member_df_display[member_df_display['ã‚³ãƒ¼ãƒ‰']==x]['åå‰'].values[0]} ({x})"
        )
    else:
        # ä¸Šä½Nåã‚’è‡ªå‹•é¸æŠ
        n_top = st.slider(
            "ä¸Šä½ä½•åã‚’é¸æŠã—ã¾ã™ã‹ï¼Ÿ",
            min_value=MIN_EXCELLENT,
            max_value=MAX_EXCELLENT_RECOMMENDED,
            value=10
        )
        top_members = member_df_display.nlargest(n_top, 'ã‚¹ã‚­ãƒ«ä¿æœ‰æ•°')
        selected_members = top_members['ã‚³ãƒ¼ãƒ‰'].tolist()

        st.info(f"ã‚¹ã‚­ãƒ«ä¿æœ‰æ•°ä¸Šä½{n_top}åã‚’è‡ªå‹•é¸æŠã—ã¾ã—ãŸ")
        st.dataframe(top_members, use_container_width=True)

    st.markdown(f"**é¸æŠã•ã‚ŒãŸç¤¾å“¡æ•°: {len(selected_members)}å**")

    if len(selected_members) < MIN_EXCELLENT:
        st.warning(f"âš ï¸ æœ€ä½{MIN_EXCELLENT}åä»¥ä¸Šã®å„ªç§€äººæã‚’é¸æŠã—ã¦ãã ã•ã„")
    elif len(selected_members) > MAX_EXCELLENT_RECOMMENDED:
        st.warning(f"âš ï¸ {MAX_EXCELLENT_RECOMMENDED}åä»¥ä¸‹ã§ã®é¸æŠã‚’æ¨å¥¨ã—ã¾ã™")

    st.markdown("---")

    # åˆ†æå®Ÿè¡Œ
    st.header("2ï¸âƒ£ åˆ†æå®Ÿè¡Œ")

    col1, col2 = st.columns([1, 3])

    with col1:
        epochs = st.number_input(
            "å­¦ç¿’ã‚¨ãƒãƒƒã‚¯æ•°",
            min_value=MIN_EPOCHS,
            max_value=MAX_EPOCHS,
            value=DEFAULT_EPOCHS,
            step=50,
            help="å­¦ç¿’ã®åå¾©å›æ•°ã€‚å¤šã„ã»ã©ç²¾åº¦ãŒä¸ŠãŒã‚Šã¾ã™ãŒæ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™"
        )

    with col2:
        epoch_recs = get_config('ui.epoch_recommendations', {})
        small = epoch_recs.get('small_group', [50, 100])
        medium = epoch_recs.get('medium_group', [100, 200])
        large = epoch_recs.get('large_group', [200, 300])

        st.info(f"""
        **æ¨å¥¨è¨­å®š**
        - å„ªç§€ç¾¤5åä»¥ä¸‹: {small[0]}-{small[1]}ã‚¨ãƒãƒƒã‚¯
        - å„ªç§€ç¾¤10åç¨‹åº¦: {medium[0]}-{medium[1]}ã‚¨ãƒãƒƒã‚¯
        - å„ªç§€ç¾¤20åä»¥ä¸Š: {large[0]}-{large[1]}ã‚¨ãƒãƒƒã‚¯
        """)

    if st.button("ğŸš€ åˆ†æé–‹å§‹", type="primary", disabled=(len(selected_members) < MIN_EXCELLENT)):
        try:
            with st.spinner("GNNãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã¨åˆ†æã‚’å®Ÿè¡Œä¸­..."):
                # Layer 1-3 é€†å‘ãå› æœæ¨è«–åˆ†æã‚’å®Ÿè¡Œ
                analyzer.train(selected_members, epochs_unsupervised=epochs)

                # Layer 1: å„ªç§€è€…ã‚¹ã‚­ãƒ«ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æ
                skill_profile = analyzer.analyze_skill_profile_of_excellent_members(selected_members)

                # Layer 2: å€‹åˆ¥ãƒ¡ãƒ³ãƒãƒ¼ã®ç•°è³ªçš„å‡¦ç½®åŠ¹æœæ¨å®š
                hte_results = analyzer.estimate_heterogeneous_treatment_effects(selected_members, skill_profile)

                # Layer 3: çµŒå–¶çš„ã‚¤ãƒ³ã‚µã‚¤ãƒˆç”Ÿæˆ
                insights = analyzer.generate_comprehensive_insights(selected_members, skill_profile, hte_results)

                # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
                st.session_state.skill_profile = skill_profile
                st.session_state.hte_results = hte_results
                st.session_state.insights = insights

            st.success("âœ… Layer 1-3 åˆ†æå®Œäº†ï¼")
        except ModelTrainingError as e:
            logger.error(f"ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            st.error(
                f"âŒ ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚\n"
                f"è©³ç´°: {str(e)}\n\n"
                f"å¯¾ç­–:\n"
                f"- ã‚¨ãƒãƒƒã‚¯æ•°ã‚’æ¸›ã‚‰ã—ã¦ã¿ã¦ãã ã•ã„\n"
                f"- å„ªç§€äººæã®äººæ•°ã‚’å¢—ã‚„ã—ã¦ã¿ã¦ãã ã•ã„"
            )
        except (CausalInferenceError, DataValidationError) as e:
            logger.error(f"åˆ†æã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            st.error(
                f"âŒ Layer 1-3 åˆ†æã®å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚\n"
                f"è©³ç´°: {str(e)}\n\n"
                f"å¯¾ç­–:\n"
                f"- å„ªç§€äººæã®äººæ•°ã‚’å¢—ã‚„ã—ã¦ã¿ã¦ãã ã•ã„ï¼ˆæ¨å¥¨: 5-10åï¼‰\n"
                f"- å¯¾è±¡ç¤¾å“¡ã®ç·æ•°ãŒååˆ†ã‹ç¢ºèªã—ã¦ãã ã•ã„ï¼ˆæ¨å¥¨: 50åä»¥ä¸Šï¼‰"
            )
        except AnalysisError as e:
            logger.error(f"åˆ†æã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            st.error(
                f"âŒ åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚\n"
                f"è©³ç´°: {str(e)}"
            )
        except Exception as e:
            logger.error(f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", exc_info=True)
            st.error(
                f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚\n"
                f"è©³ç´°: {str(e)}\n\n"
                f"ãƒ­ã‚°å‡ºåŠ›:"
            )
            import traceback
            st.error(traceback.format_exc())

    st.markdown("---")

    # Layer 1-3 é€†å‘ãå› æœæ¨è«–åˆ†æã®çµæœè¡¨ç¤º
    st.markdown("---")
    st.header("ğŸ”„ é€†å‘ãå› æœæ¨è«–åˆ†æï¼ˆæ–°æ©Ÿèƒ½ï¼‰")

    if st.session_state.data_loaded and st.session_state.analyzer is not None:
        with st.expander("ğŸ“š Layer 1-3 åˆ†æã‚’å®Ÿè¡Œ", expanded=True):

            # å„ªç§€ç¾¤ã®é¸æŠ
            selected_excellent = st.multiselect(
                "å„ªç§€ç¾¤ã¨ã—ã¦åˆ†æã™ã‚‹ç¤¾å“¡ã‚’é¸æŠï¼ˆæœ€ä½3åï¼‰",
                st.session_state.member_df['ãƒ¡ãƒ³ãƒãƒ¼ã‚³ãƒ¼ãƒ‰'].unique(),
                help="çµ±è¨ˆçš„ã«æœ‰æ„ãªçµæœã‚’å¾—ã‚‹ãŸã‚ã€5-10åã®é¸æŠã‚’æ¨å¥¨"
            )

            if len(selected_excellent) >= 3 and st.button("ğŸš€ Layer 1-3 åˆ†æã‚’å®Ÿè¡Œ"):
                try:
                    with st.spinner("Layer 1-3 åˆ†æã‚’å®Ÿè¡Œä¸­...ï¼ˆæ•°ç§’ã‹ã‹ã‚Šã¾ã™ï¼‰"):

                        # Layer 1: å„ªç§€è€…ç‰¹æ€§ã®é€†å‘ãåˆ†æ
                        logger.info(f"Layer 1ã‚’å®Ÿè¡Œä¸­: {len(selected_excellent)}äººã®å„ªç§€ç¾¤ã‚’åˆ†æ")
                        skill_profile = st.session_state.analyzer.analyze_skill_profile_of_excellent_members(
                            selected_excellent
                        )

                        # Layer 2: å€‹åˆ¥ãƒ¡ãƒ³ãƒãƒ¼ã¸ã®å› æœåŠ¹æœæ¨å®š
                        logger.info("Layer 2ã‚’å®Ÿè¡Œä¸­: å€‹åˆ¥ãƒ¡ãƒ³ãƒãƒ¼ã®å› æœåŠ¹æœã‚’æ¨å®š")
                        hte_results = st.session_state.analyzer.estimate_heterogeneous_treatment_effects(
                            selected_excellent,
                            skill_profile
                        )

                        # Layer 3: èª¬æ˜å¯èƒ½æ€§ã®å¼·åŒ–
                        logger.info("Layer 3ã‚’å®Ÿè¡Œä¸­: åŒ…æ‹¬çš„ãªåˆ†ææ´å¯Ÿã‚’ç”Ÿæˆ")
                        insights = st.session_state.analyzer.generate_comprehensive_insights(
                            selected_excellent,
                            skill_profile,
                            hte_results
                        )

                        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
                        st.session_state.skill_profile = skill_profile
                        st.session_state.hte_results = hte_results
                        st.session_state.insights = insights

                        st.success("âœ… Layer 1-3 åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼")

                except Exception as e:
                    logger.error(f"åˆ†æå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
                    st.error(f"âŒ åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

    # åˆ†æçµæœã®è¡¨ç¤º
    if hasattr(st.session_state, 'insights') and st.session_state.insights is not None:
        insights = st.session_state.insights
        skill_profile = st.session_state.skill_profile
        hte_results = st.session_state.hte_results

        st.markdown("---")

        # Layer 3ã®çµæœã‚’è¡¨ç¤º
        st.markdown(insights['executive_summary'])

        # ã‚¿ãƒ–ã§çµæœã‚’åˆ†å‰²è¡¨ç¤º
        analysis_tabs = st.tabs([
            "ğŸ¯ å„ªç§€è€…ã‚¹ã‚­ãƒ«ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«",
            "ğŸ‘¥ ãƒ¡ãƒ³ãƒãƒ¼åˆ¥æ”¹å–„ææ¡ˆ",
            "ğŸ“Š çµ„ç¹”ã‚¹ã‚­ãƒ«ã‚®ãƒ£ãƒƒãƒ—",
            "ğŸ”— ã‚¹ã‚­ãƒ«ç›¸ä¹—åŠ¹æœ",
            "ğŸ—ºï¸ é–‹ç™ºãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—"
        ])

        # Tab 1: ã‚¹ã‚­ãƒ«ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆLayer 1ï¼‰
        with analysis_tabs[0]:
            st.subheader("å„ªç§€è€…ãŒæŒã¤ã¹ãã‚¹ã‚­ãƒ« TOP 10")

            top_10_skills = skill_profile[:10]

            for idx, skill in enumerate(top_10_skills, 1):
                with st.expander(
                    f"{idx}. {skill['skill_name']} "
                    f"({skill['importance']*100:+.1f}% å·®åˆ†)"
                ):
                    col1, col2 = st.columns(2)

                    with col1:
                        st.metric(
                            "å„ªç§€ç¾¤ã§ã®ç¿’å¾—ç‡",
                            f"{skill['p_excellent']*100:.0f}%",
                            f"ä¿¡é ¼åŒºé–“: {skill['ci_excellent'][0]*100:.0f}%-{skill['ci_excellent'][1]*100:.0f}%"
                        )
                        st.metric(
                            "éå„ªç§€ç¾¤ã§ã®ç¿’å¾—ç‡",
                            f"{skill['p_control']*100:.0f}%",
                            f"ä¿¡é ¼åŒºé–“: {skill['ci_control'][0]*100:.0f}%-{skill['ci_control'][1]*100:.0f}%"
                        )

                    with col2:
                        st.metric(
                            "é‡è¦åº¦ï¼ˆå·®åˆ†ï¼‰",
                            f"{skill['importance']*100:+.1f}%"
                        )
                        st.metric(
                            "çµ±è¨ˆçš„æœ‰æ„æ€§",
                            "æœ‰æ„" if skill['significant'] else "æœ‰æ„ã§ãªã„",
                            f"p-value: {skill['p_value']:.4f}"
                        )

                    st.info(skill['interpretation'])

        # Tab 2: ãƒ¡ãƒ³ãƒãƒ¼åˆ¥æ”¹å–„ææ¡ˆï¼ˆLayer 2ï¼‰
        with analysis_tabs[1]:
            st.subheader("ãƒ¡ãƒ³ãƒãƒ¼åˆ¥æ”¹å–„ææ¡ˆï¼ˆTOP 20ï¼‰")

            recommendations = insights['member_recommendations'][:20]

            for rec in recommendations:
                with st.expander(
                    f"{rec['member_id']}: "
                    f"æ”¹å–„æœŸå¾…å€¤ {rec['estimated_improvement']*100:+.1f}%"
                ):
                    st.write(rec['summary'])

                    for skill in rec['priority_skills']:
                        col1, col2 = st.columns([2, 1])

                        with col1:
                            st.write(f"**{skill['rank']}. {skill['skill_name']}**")
                            st.caption(skill['reasoning'])

                        with col2:
                            st.metric(
                                "ä¿¡é ¼åº¦",
                                skill['confidence'],
                                f"{skill['expected_effect']*100:+.1f}%"
                            )

        # Tab 3: çµ„ç¹”ã‚¹ã‚­ãƒ«ã‚®ãƒ£ãƒƒãƒ—
        with analysis_tabs[2]:
            st.subheader("çµ„ç¹”ã‚¹ã‚­ãƒ«ã‚®ãƒ£ãƒƒãƒ—åˆ†æ")

            gaps = insights['organizational_gaps']

            col1, col2, col3 = st.columns(3)

            with col1:
                st.write("### ğŸ”´ Critical Gap")
                st.write(f"**{len(gaps['critical_gaps'])}å€‹ã®ã‚¹ã‚­ãƒ«**")
                for skill in gaps['critical_gaps'][:3]:
                    st.write(f"- {skill['skill_name']}: {skill['gap']*100:+.1f}%")

            with col2:
                st.write("### ğŸŸ¡ High Potential")
                st.write(f"**{len(gaps['high_potential_skills'])}å€‹ã®ã‚¹ã‚­ãƒ«**")
                for skill in gaps['high_potential_skills'][:3]:
                    st.write(f"- {skill['skill_name']}: {skill['importance']*100:+.1f}%")

            with col3:
                st.write("### ğŸŸ¢ Saturation")
                st.write(f"**{len(gaps['saturation_skills'])}å€‹ã®ã‚¹ã‚­ãƒ«**")
                for skill in gaps['saturation_skills'][:3]:
                    st.write(f"- {skill['skill_name']}: {skill['adoption_rate']*100:.0f}%")

        # Tab 4: ã‚¹ã‚­ãƒ«ç›¸ä¹—åŠ¹æœ
        with analysis_tabs[3]:
            st.subheader("ã‚¹ã‚­ãƒ«ç›¸ä¹—åŠ¹æœã®å¯èƒ½æ€§")

            synergies = insights['skill_combinations']

            if synergies:
                df_synergies = pd.DataFrame([
                    {
                        'ã‚¹ã‚­ãƒ«çµ„ã¿åˆã‚ã›': s['skill_combination'],
                        'ãã®ã‚¹ã‚­ãƒ«çµ„ã‚’ç¿’å¾—è€…': s['member_count_with_both'],
                        'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹': s['status']
                    }
                    for s in synergies
                ])

                st.dataframe(df_synergies, use_container_width=True)
            else:
                st.info("ç›¸ä¹—åŠ¹æœãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")

        # Tab 5: é–‹ç™ºãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—
        with analysis_tabs[4]:
            st.subheader("ã‚¹ã‚­ãƒ«é–‹ç™ºãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—")

            roadmap = insights['development_roadmap']
            resources = roadmap['resources_required']

            # ãƒªã‚½ãƒ¼ã‚¹è¦‹ç©ã‚‚ã‚Š
            col1, col2, col3 = st.columns(3)

            with col1:
                st.metric(
                    "é–‹ç™ºå¯¾è±¡ãƒ¡ãƒ³ãƒãƒ¼æ•°",
                    resources['estimated_members_to_develop']
                )

            with col2:
                st.metric(
                    "æ¨å¥¨å®Ÿæ–½æœŸé–“",
                    f"{resources['recommended_timeline_months']}ãƒ¶æœˆ"
                )

            with col3:
                st.metric(
                    "æ¨å®šç·ã‚³ã‚¹ãƒˆ",
                    f"Â¥{resources['total_estimated_cost']:,.0f}"
                )

            # å„ªå…ˆåº¦ä»˜ã‘ã‚¹ã‚­ãƒ«ãƒ—ãƒ©ãƒ³
            st.markdown("### å„ªå…ˆåº¦ä»˜ã‘ã‚¹ã‚­ãƒ«ç¿’å¾—è¨ˆç”»")

            for phase, phase_name in [
                ('immediate_priority', 'ğŸ”´ å³åº§å®Ÿæ–½ï¼ˆ1ãƒ¶æœˆä»¥å†…ï¼‰'),
                ('short_term', 'ğŸŸ¡ çŸ­æœŸè¨ˆç”»ï¼ˆ3ãƒ¶æœˆä»¥å†…ï¼‰'),
                ('medium_term', 'ğŸŸ¢ ä¸­æœŸè¨ˆç”»ï¼ˆ6ãƒ¶æœˆä»¥å†…ï¼‰')
            ]:
                with st.expander(phase_name, expanded=(phase == 'immediate_priority')):

                    plans = roadmap[phase][:10]

                    if plans:
                        df_plans = pd.DataFrame([
                            {
                                'ãƒ¡ãƒ³ãƒãƒ¼ID': p['member_id'],
                                'ã‚¹ã‚­ãƒ«': p['skill'],
                                'æœŸå¾…åŠ¹æœ': f"{p['expected_effect']*100:+.1f}%",
                                'ä¿¡é ¼åº¦': p['confidence']
                            }
                            for p in plans
                        ])

                        st.dataframe(df_plans, use_container_width=True)
                    else:
                        st.info(f"{phase_name} ã«è©²å½“ã™ã‚‹ã‚¹ã‚­ãƒ«ã¯ã‚ã‚Šã¾ã›ã‚“")


# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: gray;'>
GNNå„ªç§€äººæåˆ†æã‚·ã‚¹ãƒ†ãƒ  v2.0 | é€†å‘ãå› æœæ¨è«– + HTEåˆ†æå¯¾å¿œ | Powered by Graph Neural Networks
</div>
""", unsafe_allow_html=True)
